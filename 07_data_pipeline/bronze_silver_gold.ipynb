{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medallion Architecture: Bronze â†’ Silver â†’ Gold\n",
        "\n",
        "This notebook demonstrates the medallion architecture pattern for data processing.\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand Bronze, Silver, Gold layers\n",
        "- Implement data quality checks\n",
        "- Create business-ready datasets\n",
        "- Apply data governance principles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ¥‰ Bronze Layer: Raw Data Ingestion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw airlines data (Bronze layer)\n",
        "from pyspark.sql.functions import current_timestamp, lit\n",
        "\n",
        "# Try to load from different sources\n",
        "try:\n",
        "    # First try: Use provided input path parameter\n",
        "    input_path = \"/databricks-datasets/airlines\"  # This can be passed as parameter\n",
        "    df = spark.read.csv(input_path, header=True, inferSchema=True)\n",
        "    print(\"âœ… Loaded data from databricks-datasets\")\n",
        "except:\n",
        "    try:\n",
        "        # Second try: Use sample data from FileStore\n",
        "        df = spark.read.csv(\"/FileStore/sample_airlines.csv\", header=True, inferSchema=True)\n",
        "        print(\"âœ… Loaded sample data from FileStore\")\n",
        "    except:\n",
        "        # Third try: Create sample data\n",
        "        sample_data = [\n",
        "            (2001, 1, 1, 848, 8, 923, 3, \"AA\", 1, \"N319AA\", \"JFK\", \"LAX\", 339, 2475, 14, 8),\n",
        "            (2001, 1, 1, 850, 10, 1006, 6, \"AA\", 2, \"N319AA\", \"JFK\", \"LAX\", 336, 2475, 14, 10),\n",
        "            (2001, 1, 1, 923, 23, 1004, 4, \"AA\", 3, \"N319AA\", \"JFK\", \"LAX\", 321, 2475, 15, 23),\n",
        "            (2001, 1, 1, 1007, 7, 1130, 0, \"AA\", 4, \"N319AA\", \"JFK\", \"LAX\", 323, 2475, 16, 7),\n",
        "            (2001, 1, 1, 1249, 9, 1518, 8, \"AA\", 5, \"N319AA\", \"JFK\", \"LAX\", 329, 2475, 20, 49)\n",
        "        ]\n",
        "        columns = [\"year\", \"month\", \"day\", \"dep_time\", \"dep_delay\", \"arr_time\", \"arr_delay\", \n",
        "                  \"carrier\", \"flight\", \"tailnum\", \"origin\", \"dest\", \"air_time\", \"distance\", \"hour\", \"minute\"]\n",
        "        df = spark.createDataFrame(sample_data, columns)\n",
        "        print(\"âœ… Created sample data\")\n",
        "\n",
        "# Add metadata columns for Bronze layer\n",
        "bronze_df = df.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
        "bronze_df = bronze_df.withColumn(\"data_source\", lit(\"airlines_dataset\"))\n",
        "bronze_df = bronze_df.withColumn(\"layer\", lit(\"bronze\"))\n",
        "\n",
        "print(f\"Bronze Layer - Raw Data:\")\n",
        "print(f\"Records: {bronze_df.count()}\")\n",
        "print(f\"Columns: {len(bronze_df.columns)}\")\n",
        "bronze_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Bronze layer\n",
        "bronze_path = \"/delta/airlines_bronze\"  # This can be passed as parameter\n",
        "bronze_df.write.format(\"delta\").mode(\"overwrite\").save(bronze_path)\n",
        "print(f\"âœ… Bronze layer saved to: {bronze_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ¥ˆ Silver Layer: Cleaned & Validated Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Bronze data and clean it (Silver layer)\n",
        "from pyspark.sql.functions import col, when, isnan, isnull, trim, upper\n",
        "\n",
        "bronze_df = spark.read.format(\"delta\").load(bronze_path)\n",
        "\n",
        "print(\"Data Quality Checks:\")\n",
        "print(f\"Total records: {bronze_df.count()}\")\n",
        "print(f\"Records with null carrier: {bronze_df.filter(bronze_df.carrier.isNull()).count()}\")\n",
        "print(f\"Records with null flight: {bronze_df.filter(bronze_df.flight.isNull()).count()}\")\n",
        "\n",
        "# Clean and validate data\n",
        "silver_df = (bronze_df.filter(\n",
        "    col(\"carrier\").isNotNull() & \n",
        "    col(\"flight\").isNotNull() &\n",
        "    col(\"origin\").isNotNull() &\n",
        "    col(\"dest\").isNotNull()\n",
        ")\n",
        ".withColumn(\"carrier\", trim(upper(col(\"carrier\"))))\n",
        ".withColumn(\"origin\", trim(upper(col(\"origin\"))))\n",
        ".withColumn(\"dest\", trim(upper(col(\"dest\"))))\n",
        ".withColumn(\"layer\", lit(\"silver\"))\n",
        ".withColumn(\"processing_timestamp\", current_timestamp()))\n",
        "\n",
        "print(f\"\\nSilver Layer - Cleaned Data:\")\n",
        "print(f\"Records after cleaning: {silver_df.count()}\")\n",
        "silver_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Silver layer\n",
        "silver_path = \"/delta/airlines_silver\"  # This can be passed as parameter\n",
        "silver_df.write.format(\"delta\").mode(\"overwrite\").save(silver_path)\n",
        "print(f\"âœ… Silver layer saved to: {silver_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ¥‡ Gold Layer: Business-Ready Aggregations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Silver data and create business metrics (Gold layer)\n",
        "from pyspark.sql.functions import count, avg, sum, max, min\n",
        "\n",
        "silver_df = spark.read.format(\"delta\").load(silver_path)\n",
        "\n",
        "# Create carrier performance metrics\n",
        "carrier_metrics = (silver_df.groupBy(\"carrier\").agg(\n",
        "    count(\"*\").alias(\"total_flights\"),\n",
        "    avg(\"dep_delay\").alias(\"avg_departure_delay\"),\n",
        "    avg(\"arr_delay\").alias(\"avg_arrival_delay\"),\n",
        "    avg(\"distance\").alias(\"avg_distance\")\n",
        ")\n",
        ".withColumn(\"layer\", lit(\"gold\"))\n",
        ".withColumn(\"aggregation_timestamp\", current_timestamp()))\n",
        "\n",
        "print(\"Gold Layer - Carrier Metrics:\")\n",
        "carrier_metrics.show()\n",
        "\n",
        "# Save Gold layer\n",
        "gold_path = \"/delta/airlines_gold\"  # This can be passed as parameter\n",
        "carrier_metrics.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
        "print(f\"âœ… Gold layer saved to: {gold_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Pipeline Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline summary\n",
        "bronze_count = spark.read.format(\"delta\").load(bronze_path).count()\n",
        "silver_count = spark.read.format(\"delta\").load(silver_path).count()\n",
        "gold_count = spark.read.format(\"delta\").load(gold_path).count()\n",
        "\n",
        "print(\"ðŸ“ˆ Medallion Architecture Summary:\")\n",
        "print(f\"ðŸ¥‰ Bronze Layer: {bronze_count:,} raw records\")\n",
        "print(f\"ðŸ¥ˆ Silver Layer: {silver_count:,} cleaned records\")\n",
        "print(f\"ðŸ¥‡ Gold Layer: {gold_count} business metrics\")\n",
        "print(f\"ðŸ“Š Data Quality: {((silver_count/bronze_count)*100):.1f}% records passed validation\")\n",
        "\n",
        "print(\"\\nâœ… Medallion Architecture pipeline completed successfully!\")\n",
        "print(\"ðŸŽ¯ All layers (Bronze â†’ Silver â†’ Gold) processed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
