{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Quality Checks\n",
        "\n",
        "This notebook performs comprehensive data quality validation on the processed datasets.\n",
        "\n",
        "## Learning Objectives\n",
        "- Implement data quality checks\n",
        "- Monitor data freshness\n",
        "- Validate data completeness\n",
        "- Generate quality reports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the table to validate\n",
        "table_path = \"/delta/airlines_gold\"  # This will be passed as parameter\n",
        "df = spark.read.format(\"delta\").load(table_path)\n",
        "\n",
        "print(f\"Data Quality Check for: {table_path}\")\n",
        "print(f\"Total records: {df.count()}\")\n",
        "print(f\"Columns: {len(df.columns)}\")\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Quality Checks\n",
        "from pyspark.sql.functions import col, count, isnan, isnull, sum as spark_sum\n",
        "\n",
        "print(\"=== DATA QUALITY REPORT ===\")\n",
        "\n",
        "# 1. Check for null values\n",
        "print(\"\\n1. NULL VALUE ANALYSIS:\")\n",
        "for column in df.columns:\n",
        "    null_count = df.filter(col(column).isNull()).count()\n",
        "    total_count = df.count()\n",
        "    null_percentage = (null_count / total_count) * 100 if total_count > 0 else 0\n",
        "    print(f\"  {column}: {null_count} nulls ({null_percentage:.2f}%)\")\n",
        "\n",
        "# 2. Check for duplicate records\n",
        "print(\"\\n2. DUPLICATE ANALYSIS:\")\n",
        "duplicate_count = df.count() - df.dropDuplicates().count()\n",
        "print(f\"  Duplicate records: {duplicate_count}\")\n",
        "\n",
        "# 3. Data freshness check\n",
        "print(\"\\n3. DATA FRESHNESS:\")\n",
        "if \"processing_timestamp\" in df.columns:\n",
        "    latest_timestamp = df.select(\"processing_timestamp\").orderBy(col(\"processing_timestamp\").desc()).first()[0]\n",
        "    print(f\"  Latest processing time: {latest_timestamp}\")\n",
        "else:\n",
        "    print(\"  No timestamp column found\")\n",
        "\n",
        "# 4. Data distribution\n",
        "print(\"\\n4. DATA DISTRIBUTION:\")\n",
        "df.describe().show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
